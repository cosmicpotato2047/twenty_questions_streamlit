import streamlit as st
from ollama_llm import get_ollama_llm

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPT = '''
You are playing a game of Twenty Questions. Think of an English noun. Ask yes/no questions to guess the noun within 20 questions. When you're ready to guess, ask in the form "Is it a [object]?".
'''

# ì…ë ¥ ì²˜ë¦¬ ì½œë°±
def handle_answer():
    ans = st.session_state.input.strip().lower()
    # ì…ë ¥ ì´ˆê¸°í™”
    st.session_state.input = ''
    # ìœ íš¨ ë‹µë³€ ëª©ë¡
    valid = ['yes', 'no', "i don't know", 'it depends', 'quit']
    if ans not in valid:
        # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€í•˜ì—¬ í‘œì‹œ
        st.session_state.history.append({'role': 'assistant', 'content':
            "ìœ íš¨í•˜ì§€ ì•Šì€ ë‹µë³€ì…ë‹ˆë‹¤. yes, no, I donâ€™t know, it depends ì¤‘ í•˜ë‚˜ë¡œ ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”."})
        return
    # ì‚¬ìš©ì ì‘ë‹µ ê¸°ë¡
    st.session_state.history.append({'role': 'user', 'content': ans})
    last_q = st.session_state.history[-2]['content'].lower()
    # ì¢…ë£Œ ì²˜ë¦¬
    if ans == 'quit':
        st.session_state.history.append({'role': 'assistant', 'content': 'ê²Œì„ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.'})
        st.session_state.game_over = True
        return
    if last_q.startswith('is it'):
        if ans == 'yes':
            st.session_state.history.append({'role': 'assistant', 'content': 'AI ìŠ¹ë¦¬!'})
        else:
            st.session_state.history.append({'role': 'assistant', 'content': 'AI íŒ¨ë°°!'})
        st.session_state.game_over = True
        return
    # ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±
    if st.session_state.count < 20:
        llm = get_ollama_llm()
        prompt = "".join([
            f"{m['role']}: {m['content']}\n" for m in st.session_state.history
        ]) + "AI:"
        result = llm.generate([prompt])
        question = result.generations[0][0].text.strip()
        st.session_state.history.append({'role': 'assistant', 'content': question})
        st.session_state.count += 1
    else:
        # 20ë²ˆì§¸ ì´í›„ ìë™ ì¶”ì¸¡
        llm = get_ollama_llm()
        prompt = "".join([
            f"{m['role']}: {m['content']}\n" for m in st.session_state.history
        ]) + "AI:"
        result = llm.generate([prompt])
        guess = result.generations[0][0].text.strip()
        st.session_state.history.append({'role': 'assistant', 'content': guess})
        st.session_state.count += 1

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'history' not in st.session_state:
    st.session_state.history = [{'role': 'system', 'content': SYSTEM_PROMPT}]
    st.session_state.count = 0
    st.session_state.game_over = False
    st.session_state.input = ''

st.title("ğŸ•µï¸â€â™‚ï¸ ìŠ¤ë¬´ê³ ê°œ ê²Œì„")

# ê²Œì„ ì‹œì‘ ë²„íŠ¼
if st.button("ìƒˆ ê²Œì„ ì‹œì‘"):
    st.session_state.history = [{'role': 'system', 'content': SYSTEM_PROMPT}]
    st.session_state.count = 0
    st.session_state.game_over = False
    # ì²« ì§ˆë¬¸ ìƒì„±
    llm = get_ollama_llm()
    prompt = "".join([
        f"{m['role']}: {m['content']}\n" for m in st.session_state.history
    ]) + "AI:"
    result = llm.generate([prompt])
    question = result.generations[0][0].text.strip()
    st.session_state.history.append({'role': 'assistant', 'content': question})
    st.session_state.count += 1

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶œë ¥
for msg in st.session_state.history[1:]:  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì œì™¸
    if msg['role'] == 'assistant':
        st.chat_message('assistant').write(msg['content'])
    elif msg['role'] == 'user':
        st.chat_message('user').write(msg['content'])

# ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸ë°•ìŠ¤ (ì—”í„°ë¡œ ì œì¶œ)
st.text_input(
    "A) yes / no / I don't know / it depends",
    key='input',
    on_change=handle_answer,
    disabled=st.session_state.game_over
)